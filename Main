import PySimpleGUI as sg
import requests
import os
import threading
from bs4 import BeautifulSoup

class PDFScraper:
    def __init__(self):
        # Create the layout of the user interface
        layout = [
            [sg.Text("Enter the URL of the site to search for PDFs:")],
            [sg.Input(key="url")],
            [sg.Text("Enter the number of pages to search:")],
            [sg.Input(key="num_pages")],
            [sg.Button("Search and Download PDFs", key="search"), sg.Button("Cancel")],
            [sg.ProgressBar(100, orientation="h", size=(20, 20), key="progress")],
            [sg.Output(size=(80, 20))]
        ]

        # Create the window with the layout
        self.window = sg.Window("PDF Scraper", layout)
    
    def start(self):
        while True:
            # Get the user input and the button that was clicked
            event, values = self.window.read()

            # If the user clicks the "Search and Download PDFs" button
            if event == "search":
                # Get the URL and number of pages entered by the user
                url = values["url"]
                num_pages = int(values["num_pages"])

                # Create a list to store the PDF links found on each page
                pdf_links = []

                for page in range(1, num_pages + 1):
                    # Construct the URL for the current page
                    page_url = url + "?page=" + str(page)

                    # Send a GET request to the URL
                    try:
                        response = requests.get(page_url)
                        response.raise_for_status()  # Check for HTTP errors
                    except requests.exceptions.RequestException as e:
                        sg.popup_error("Invalid URL: " + str(e))
                        return

                    # Parse the HTML content of the page
                    html_soup = BeautifulSoup(response.content, "html.parser")

                    # Find all PDF links on the page
                    page_pdf_links = [a["href"]
                                      for a in html_soup.find_all("a", href=True)
                                      if a["href"].endswith(".pdf")]

                    # Add the PDF links from the current page to the list
                    pdf_links += page_pdf_links

                # Prompt the user to select a directory to save the PDFs to
                directory = sg.popup_get_folder("Select directory to save PDFs")

                if not directory:
                    return

                # Start a thread to download PDFs and update the progress bar
                progress_bar = self.window["progress"]
                thread = threading.Thread(target=self.download_pdfs, args=(pdf_links, directory, progress_bar))
                thread.start()

            # If the user clicks the "Cancel" button or closes the window
            elif event in (None, "cancel"):
                # Close the window and exit the application
                self.window.close()
                return
    
    def download_pdfs(self, pdf_links, directory, progress_bar):
        total_pdfs = len(pdf_links)
        progress_value = 0

        for link in pdf_links:
            progress_value += 1
            progress_bar.UpdateBar((progress_value / total_pdfs) * 100)

            # Download and save each PDF to the selected directory
            self.download_pdf(link, directory)

    def download_pdf(self, link, directory):
        # Extract the filename from the URL
        filename = link.split("/")[-1]
        file_path = os.path.join(directory, filename)

        try:
            # Send a GET request to download the PDF
            response = requests.get(link, stream=True)
            response.raise_for_status()  # Check for HTTP errors

            # Save the PDF to the file
            with open(file_path, "wb") as file:
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        file.write(chunk)
        except requests.exceptions.RequestException as e:
            print("Error downloading PDF:", str(e))
        except IOError as e:
            print("Error saving PDF:", str(e))

# Create an instance of the PDFScraper class
pdf_scraper = PDFScraper()
pdf_scraper.start()
